{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patitimoner/itai2377-datasets/blob/main/ITAI2377_Lab_Student_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, here's the complete code and markdown, broken into blocks as requested, to create a well-structured Colab notebook addressing the instructions.\n",
        "\n",
        "**Notebook Title:** `L02_Your_Name_ITAI_2377.ipynb`\n",
        "\n",
        "---\n",
        "\n",
        "### **Markdown Cell 1: Introduction**\n",
        "\n",
        "```markdown\n",
        "# Lesson 2: Understanding Different Data Types for AI\n",
        "\n",
        "**Author:** [Your Name]\n",
        "**Course:** ITAI 2377\n",
        "\n",
        "This notebook explores how AI systems process various data types, including structured, image, and text data. We will load datasets, examine their characteristics, and discuss conceptual questions related to AI's ability to understand and interpret these different formats.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Code Cell 1: Clone the Dataset Repository**"
      ],
      "metadata": {
        "id": "2QDNEa7Af3HP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the entire dataset repository\n",
        "!git clone https://github.com/patitimoner/itai2377-datasets.git\n",
        "%cd itai2377-datasets\n",
        "!ls"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "oPLFrdiXf3HU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **Markdown Cell 2: Conceptual Question - Dataset Repository**\n",
        "\n",
        "```markdown\n",
        "üëâ **Conceptual Question:** Why is it beneficial to use a shared dataset repository rather than each student downloading datasets manually?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "Using a shared dataset repository offers several advantages:\n",
        "\n",
        "1.  **Consistency:** Ensures everyone works with the same data version, avoiding discrepancies in analysis and results.\n",
        "2.  **Efficiency:** Reduces redundant downloads and saves bandwidth and storage space.\n",
        "3.  **Maintainability:** Makes it easier to update or correct datasets centrally. Any changes are immediately reflected for all users.\n",
        "4.  **Reproducibility:** Facilitates reproducible research, as everyone has access to the exact same data source.\n",
        "5.  **Collaboration:** Promotes collaboration among students and researchers by providing a common data foundation.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Markdown Cell 3: Part 3 - Understanding Structured Data**\n",
        "\n",
        "```markdown\n",
        "## üìä Part 3: Understanding Structured Data (Tabular Data)\n",
        "\n",
        "Structured data, often stored in tables with rows and columns, is a common data type in various fields like finance, healthcare, and e-commerce.  AI systems can analyze this data to find patterns, make predictions, and automate decisions.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Code Cell 2: Load and Explore Customer Dataset**"
      ],
      "metadata": {
        "id": "LRP-1KSaf3HW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load structured dataset from the cloned repository\n",
        "df = pd.read_csv(\"data/structured/customer_data.csv\")\n",
        "\n",
        "# Display the first few rows\n",
        "df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "dz42b742f3HY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **Markdown Cell 4: Conceptual Question - Customer Purchase Prediction**\n",
        "\n",
        "```markdown\n",
        "üëâ **Conceptual Question:** If an AI system were built to predict customer purchases, what kind of patterns would it need to detect?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "To predict customer purchases, an AI system would need to identify various patterns, including:\n",
        "\n",
        "1.  **Demographics:** Age, gender, location, etc., might correlate with purchasing behavior.\n",
        "2.  **Past Purchase History:** Frequency, recency, and types of items bought can indicate future preferences.\n",
        "3.  **Product Relationships:** Customers who buy product A might also be likely to buy product B.\n",
        "4.  **Seasonal Trends:** Certain products might sell more during specific times of the year.\n",
        "5.  **External Factors:** Economic conditions, promotions, or even the weather can influence purchasing decisions.\n",
        "6.  **Customer Segmentation:** Grouping customers with similar characteristics can help tailor predictions.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Markdown Cell 5: Part 4 - Understanding Image Data**\n",
        "\n",
        "```markdown\n",
        "## üñºÔ∏è Part 4: Understanding Image Data (Computer Vision)\n",
        "\n",
        "Image data, unlike structured data, is represented as grids of pixels. Computer vision, a subfield of AI, focuses on enabling computers to \"see\" and interpret images.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Code Cell 3: Load CIFAR-10 with TensorFlow/Keras**"
      ],
      "metadata": {
        "id": "bBQMErzZf3HY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Select 10 images per class\n",
        "images_per_class = 10\n",
        "selected_images = []\n",
        "selected_labels = []\n",
        "\n",
        "for class_label in range(10):  # CIFAR-10 has 10 classes\n",
        "    indices = np.where(y_train == class_label)[0][:images_per_class]\n",
        "    selected_images.extend(x_train[indices])\n",
        "    selected_labels.extend(y_train[indices])\n",
        "\n",
        "# ‚ú® TIP: The code above filters images based on class labels using NumPy's `where` function."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "SJuk3oZxf3HZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **Code Cell 4: Load CIFAR-10 with PyTorch (TorchVision)**"
      ],
      "metadata": {
        "id": "Y-lFZ8Xif3Ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# Load CIFAR-10 dataset from TorchVision\n",
        "dataset = torchvision.datasets.CIFAR10(\n",
        "    root=\"./data\", train=True, download=True, transform=transforms.ToTensor()\n",
        ")\n",
        "\n",
        "# Extract a subset of 10 images per class\n",
        "images_per_class = 10\n",
        "selected_indices = []\n",
        "\n",
        "for class_label in range(10):\n",
        "    class_indices = [\n",
        "        i for i, (_, label) in enumerate(dataset) if label == class_label\n",
        "    ]\n",
        "    selected_indices.extend(class_indices[:images_per_class])\n",
        "\n",
        "subset = Subset(dataset, selected_indices)\n",
        "\n",
        "# ‚ú® TIP: PyTorch's `Subset` allows sampling specific indices from a dataset."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "dBPtSuC8f3Ha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **Markdown Cell 6: Conceptual Question - AI vs. Human Image Recognition**\n",
        "\n",
        "```markdown\n",
        "üëâ **Conceptual Question:** Why does AI need millions of images to accurately classify objects, while humans can recognize patterns with just a few examples?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "This difference stems from how humans and AI \"learn\":\n",
        "\n",
        "1.  **Abstraction and Generalization:** Humans excel at abstracting concepts and generalizing from limited examples. We can recognize a cat from various angles, lighting conditions, and breeds after seeing only a few.\n",
        "2.  **Prior Knowledge and Context:** Humans leverage a vast amount of background knowledge and contextual understanding. We know what a cat is, its typical features, and how it differs from other animals.\n",
        "3.  **Feature Extraction:** Human brains are incredibly efficient at extracting relevant features from images, focusing on key characteristics that define an object.\n",
        "4.  **AI's Data Dependency:** AI, especially deep learning models, learns by identifying statistical patterns in vast datasets. It needs numerous examples to learn the variations and nuances of each object class.\n",
        "5.  **Lack of Common Sense:** AI currently lacks the \"common sense\" reasoning that humans possess, making it harder to generalize from limited data.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Markdown Cell 7: Part 5 - Understanding Text Data**\n",
        "\n",
        "```markdown\n",
        "## üìù Part 5: Understanding Text Data (Natural Language Processing)\n",
        "\n",
        "Text data presents unique challenges for AI due to its inherent ambiguity, context-dependent meaning, and the presence of figurative language like sarcasm and metaphors. Natural Language Processing (NLP) is the field dedicated to enabling computers to understand and process human language.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Code Cell 5: Read a Sample Text File**"
      ],
      "metadata": {
        "id": "xdYkQFiRf3Hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and display a sample news article\n",
        "\n",
        "# Replace with a valid path to a text file if you want to read a file.\n",
        "# For example: sample_article_path = \"data/text/bbc_news/tech/001.txt\"\n",
        "\n",
        "try:\n",
        "    with open(sample_article_path, \"r\") as file:\n",
        "        content = file.read()\n",
        "        print(content)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at path: {sample_article_path}\")\n",
        "    print(\"Please make sure to provide a valid path to a text file within the cloned repository.\")\n",
        "\n",
        "# ‚ú® TIP: The `open()` function with the \"r\" mode allows you to read a file in Python."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "rf_X-6RVf3Hc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **Markdown Cell 8: Conceptual Question - AI and Text Ambiguity**\n",
        "\n",
        "```markdown\n",
        "üëâ **Conceptual Question:** Why do AI models struggle to understand sarcasm and context in text processing?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "Sarcasm and context pose significant challenges for AI because:\n",
        "\n",
        "1.  **Literal Interpretation:** AI tends to interpret text literally, while sarcasm relies on conveying a meaning opposite to the literal words.\n",
        "2.  **Contextual Nuances:** Understanding sarcasm often requires recognizing subtle cues, background knowledge, and the speaker's intent, which are difficult for AI to grasp.\n",
        "3.  **Figurative Language:** Sarcasm is a form of figurative language, and AI struggles to understand metaphors, idioms, and other non-literal expressions.\n",
        "4.  **Lack of World Knowledge:** AI lacks the broad \"world knowledge\" and common sense that humans use to infer the true meaning behind sarcastic remarks.\n",
        "5.  **Data Bias:** If the training data doesn't adequately represent sarcastic language, the AI model will be less accurate in detecting it.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Markdown Cell 9: Discussion Questions**\n",
        "\n",
        "```markdown\n",
        "## üß† Discussion Questions\n",
        "\n",
        "**1. How does AI process structured, image, and text data differently?**\n",
        "\n",
        "*   **Structured Data:** AI analyzes structured data using statistical methods and machine learning algorithms to find patterns, correlations, and make predictions based on numerical and categorical features.\n",
        "*   **Image Data:** AI processes images using computer vision techniques, primarily convolutional neural networks (CNNs), to extract features from pixel data, identify objects, and classify images.\n",
        "*   **Text Data:** AI handles text data through natural language processing (NLP) techniques, including tokenization, word embeddings, and recurrent neural networks (RNNs) or transformers, to understand the meaning, sentiment, and context of text.\n",
        "\n",
        "**2. What real-world AI applications combine multiple types of data (structured, image, text)?**\n",
        "\n",
        "*   **Autonomous Vehicles:** Combine sensor data (structured), camera images (image), and map data (structured/text) for navigation and decision-making.\n",
        "*   **Medical Diagnosis:** Integrate patient records (structured), medical images (image), and doctor's notes (text) for accurate diagnoses.\n",
        "*   **E-commerce Recommendations:** Use customer purchase history (structured), product images (image), and product descriptions (text) to personalize recommendations.\n",
        "*   **Social Media Analysis:** Analyze user profiles (structured), posts (text), and shared images (image) to understand public opinion and trends.\n",
        "*   **Fraud Detection:** Combine transaction data (structured), user location (structured), and textual descriptions of transactions to detect fraudulent activity.\n",
        "\n",
        "**3. Imagine you're building an AI personal assistant. What type of data would it need?**\n",
        "\n",
        "An AI personal assistant would require a wide range of data, including:\n",
        "\n",
        "*   **User's Calendar and Schedule (Structured):** To manage appointments and provide reminders.\n",
        "*   **Contacts (Structured):** To make calls, send messages, and manage communications.\n",
        "*   **Emails and Messages (Text):** To understand and respond to communications.\n",
        "*   **Voice Commands (Audio/Text):** To process user requests and interact naturally.\n",
        "*   **Location Data (Structured):** To provide location-based services and recommendations.\n",
        "*   **User Preferences (Structured/Text):** To personalize the assistant's responses and suggestions.\n",
        "*   **Web Browsing History (Structured/Text):** To understand user interests and provide relevant information.\n",
        "*   **News and Information (Text):** To answer questions and provide updates on current events.\n",
        "*   **Potentially, images from the user's camera (Image):** For visual tasks or context awareness.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Markdown Cell 10: Conclusion**\n",
        "\n",
        "```markdown\n",
        "## üí° Takeaway: AI Needs the Right Data\n",
        "\n",
        "This notebook demonstrated that AI systems rely heavily on data to function effectively. Different data types require specialized processing techniques. Understanding these fundamentals is crucial for anyone working with or building AI systems. The ability to process and interpret diverse data is essential for creating AI that can truly understand and interact with the world.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**Remember to replace placeholders like `[Your Name]` with your actual information.**\n",
        "\n",
        "**Save the notebook as:** `L02_Your_Name_ITAI_2377.ipynb`\n",
        "\n",
        "**Submit the `.ipynb` notebook as a PDF on Canvas.**\n",
        "\n",
        "I hope this comprehensive breakdown is helpful! Let me know if you have any other questions."
      ],
      "metadata": {
        "id": "cU-8meCMf3Hc"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}